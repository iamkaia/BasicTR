{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "import f5_tts\n",
    "print(dir(f5_tts))  # 查看 f5_tts 模塊中的所有對象\n",
    "import sys\n",
    "sys.path.append(\"/home/kaia/BasicTR/F5-TTS/src/f5_tts/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaia/miniforge3/envs/env-tts/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msocket_server\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TTSStreamingProcessor\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# 假設 `TTS` 是 F5-TTS 模塊的主要接口類\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 初始化 TTS 模型\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tts \u001b[38;5;241m=\u001b[39m TTSStreamingProcessor(model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/kaia/F5-TTS_Emilia-ZH-EN/F5TTS_Base\u001b[39m\u001b[38;5;124m\"\u001b[39m, config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/kaia/F5-TTS_Emilia-ZH-EN/configuration.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/BasicTR/F5-TTS/src/f5_tts/socket_server.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minfer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils_infer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_batch_process, preprocess_ref_audio_text, load_vocoder, load_model\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbones\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiT\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTTSStreamingProcessor\u001b[39;00m:\n",
      "File \u001b[0;32m~/BasicTR/F5-TTS/src/f5_tts/infer/utils_infer.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vocos\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CFM\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     get_tokenizer,\n\u001b[1;32m     29\u001b[0m     convert_char_to_pinyin,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m _ref_audio_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/BasicTR/F5-TTS/src/f5_tts/model/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbones\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiT\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbones\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmdit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MMDiT\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCFM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNetT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMMDiT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/BasicTR/F5-TTS/src/f5_tts/model/trainer.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CFM\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DynamicBatchSampler, collate_fn\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf5_tts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default, exists\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# trainer\u001b[39;00m\n",
      "File \u001b[0;32m~/BasicTR/F5-TTS/src/f5_tts/model/dataset.py:83\u001b[0m\n\u001b[1;32m     75\u001b[0m         text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     78\u001b[0m             mel_spec\u001b[38;5;241m=\u001b[39mmel_spec,\n\u001b[1;32m     79\u001b[0m             text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m     80\u001b[0m         )\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m(Dataset):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     86\u001b[0m         custom_dataset: Dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m         mel_spec_module: nn\u001b[38;5;241m.\u001b[39mModule \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     96\u001b[0m     ):\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m custom_dataset\n",
      "File \u001b[0;32m~/BasicTR/F5-TTS/src/f5_tts/model/dataset.py:95\u001b[0m, in \u001b[0;36mCustomDataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m(Dataset):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     86\u001b[0m         custom_dataset: Dataset,\n\u001b[1;32m     87\u001b[0m         durations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m         target_sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24_000\u001b[39m,\n\u001b[1;32m     89\u001b[0m         hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     90\u001b[0m         n_mel_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     91\u001b[0m         n_fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     92\u001b[0m         win_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     93\u001b[0m         mel_spec_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocos\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m         preprocessed_mel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m---> 95\u001b[0m         mel_spec_module: \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     96\u001b[0m     ):\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m custom_dataset\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdurations \u001b[38;5;241m=\u001b[39m durations\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from f5_tts.socket_server import TTSStreamingProcessor\n",
    "  # 假設 `TTS` 是 F5-TTS 模塊的主要接口類\n",
    "\n",
    "# 初始化 TTS 模型\n",
    "tts = TTSStreamingProcessor(model_path=\"/home/kaia/F5-TTS_Emilia-ZH-EN/F5TTS_Base\", config_path=\"/home/kaia/F5-TTS_Emilia-ZH-EN/configuration.json\")\n",
    "\n",
    "# 合成語音\n",
    "text = \"Hello, this is a test of the F5-TTS system.\"\n",
    "audio = tts.synthesize(text)\n",
    "\n",
    "# 將合成的音頻保存為文件\n",
    "from scipy.io.wavfile import write\n",
    "write(\"output.wav\", tts.sample_rate, audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from f5_tts.infer.utils_infer import infer_batch_process, preprocess_ref_audio_text, load_vocoder, load_model\n",
    "\n",
    "# 加載模型和配置文件\n",
    "model_path = \"/path/to/your/model.pth\"  # 替換為實際模型路徑\n",
    "config_path = \"/path/to/your/config.json\"  # 替換為實際配置文件路徑\n",
    "\n",
    "# 加載 TTS 模型和聲碼器\n",
    "tts_model = load_model(model_path, config_path)\n",
    "vocoder = load_vocoder(config_path)\n",
    "\n",
    "# 定義要生成的文本\n",
    "text_to_generate = \"Hello, this is a test of F5-TTS.\"\n",
    "\n",
    "# 如果需要使用參考音頻，可以指定路徑\n",
    "ref_audio_path = \"path/to/ref_audio.wav\"  # 替換為實際參考音頻路徑\n",
    "\n",
    "# 預處理參考音頻和文本\n",
    "ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_path, text_to_generate)\n",
    "\n",
    "# 推理生成語音\n",
    "generated_audio = infer_batch_process(\n",
    "    model=tts_model,\n",
    "    vocoder=vocoder,\n",
    "    ref_audio=ref_audio,\n",
    "    ref_text=ref_text,\n",
    "    gen_text=text_to_generate\n",
    ")\n",
    "\n",
    "# 將生成的音頻保存為文件\n",
    "from scipy.io.wavfile import write\n",
    "write(\"output_audio.wav\", vocoder.sample_rate, generated_audio)\n",
    "\n",
    "print(\"Generated audio saved to output_audio.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
